<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Noticias Tecnológicas</title>
    <link rel="stylesheet" href="Notcia.css" type="text/css" />

</head>

<body>

    <!--Botón con link a ir a la sección principal -->
    <a href='/WorkShop4/Index.html' class="btn"> Back</a>

    <!-- Encabezado del peridico -->
    <hr />

    <header class="contenedor-header">
        <h1>
            <span class="azul-oscuro">World Report</span>
            <span class="azul-claro">Newspaper</span>
        </h1>
        <p class="fecha"> June 11, 2024 </p>
    </header>

    <hr />

    <!--Imagen de la inteligencia artificial -->


    <!-- Contenedor de la imagen y el texto -->
    <div class="contenedor-noticia">
        <!-- Imagen de la inteligencia artificial -->
        <div class="imagen-noticia">
            <img src="technology-blackwhite.jpg" />
        </div>

        <!-- Texto junto a la imagen -->
        <div class="texto-noticia">
            <h2> Carta abierta de los expertos de OpenAI advierte sobre “riesgos graves” y pide protección para los
                denunciantes </h2>
            <p> A group of experts from OpenAI is demanding that artificial intelligence companies be much more
                transparent about the "serious risks" of AI and that they protect employees who express concerns about
                the technology they are developing.
                "Artificial intelligence companies have strong financial incentives to avoid effective oversight," reads
                the open letter published on Tuesday and signed by current and former employees of artificial
                intelligence companies, including OpenAI, the creator behind the famous ChatGPT tool.
                They also called on artificial intelligence companies to foster "a culture of open criticism" that
                welcomes, rather than punishes, individuals who voice concerns, especially when the law struggles to
                keep up with the rapid advancement of technology.
                Companies have acknowledged the "serious risks" posed by AI -- from manipulation to a loss of control,
                known as "singularity," which could potentially result in human extinction -- but they should do more to
                educate the public about the risks and protective measures, the group wrote.
                As the law stands, AI employees said they do not believe AI companies voluntarily share key information
                about the technology.
                <br />
                It is essential, then, that current and former employees speak out and that companies do not enforce
                "gag" agreements or retaliate against those who raise concerns related to risk. "Ordinary whistleblower
                protections are inadequate because they focus on illegal activities, while many of the risks we are
                concerned about are still unregulated," wrote the group.
                Their letter comes at a time when companies are rushing to implement generative AI tools in their
                products, while government regulators, businesses, and consumers struggle for responsible use.
                Meanwhile, many technology experts, researchers, and leaders have called for a temporary pause in the AI
                race, or for government intervention and a moratorium to be created.
                <br /><br /><br /><br />
                News written by: Samantha Murphy Kelly
                <br />
                CNN
            </p>

        </div>
    </div>

    <!--Video de la inteligencia artificial 
    <div class="video-container">
        <h2>WHAT IS ARTIFICIAL INTELLIGENCE</h2>
        <p> Watch the video..</p>
        <video controls autoplay>
            <source src="AI.mp4" type="video/mp4">
            Tu navegador no soporta la etiqueta de video.
        </video>
    </div>
    -->




</body>

</html>