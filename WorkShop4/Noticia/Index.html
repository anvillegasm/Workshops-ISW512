<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Noticias Tecnológicas</title>
    <link rel="stylesheet" href="Notcia.css" type="text/css" />

</head>

<body>

    <!--Botón con link a ir a la sección principal -->
    <a href='/WorkShop4/Index.html' class="btn"> Back</a>

    <!-- Encabezado del peridico -->
    <hr />

    <header class="contenedor-header">
        <h1>
            <span class="azul-oscuro">World Report</span>
            <span class="azul-claro">Newspaper</span>
        </h1>
        <p class="fecha"> June 11, 2024 </p>
    </header>

    <hr />

    <!--Imagen de la inteligencia artificial -->


    <!-- Contenedor de la imagen y el texto -->
    <div class="contenedor-noticia">
        <!-- Imagen de la inteligencia artificial -->
        <div class="imagen-noticia">
            <img src="technology-blackwhite.jpg" />
        </div>

        <!-- Texto junto a la imagen -->
        <div class="texto-noticia">
            <h2> Open letter from OpenAI experts warns of "serious risks" and calls for protection for whistleblowers
            </h2>
            <p> A group of experts from OpenAI is demanding that artificial intelligence companies be much more
                transparent about the "serious risks" of AI and that they protect employees who express concerns about
                the technology they are developing.
                "Artificial intelligence companies have strong financial incentives to avoid effective oversight," reads
                the open letter published on Tuesday and signed by current and former employees of artificial
                intelligence companies, including OpenAI, the creator behind the famous ChatGPT tool.
                They also called on artificial intelligence companies to foster "a culture of open criticism" that
                welcomes, rather than punishes, individuals who voice concerns, especially when the law struggles to
                keep up with the rapid advancement of technology.
                Companies have acknowledged the "serious risks" posed by AI -- from manipulation to a loss of control,
                known as "singularity," which could potentially result in human extinction -- but they should do more to
                educate the public about the risks and protective measures, the group wrote.
                As the law stands, AI employees said they do not believe AI companies voluntarily share key information
                about the technology.
                <br />
                It is essential, then, that current and former employees speak out and that companies do not enforce
                "gag" agreements or retaliate against those who raise concerns related to risk. "Ordinary whistleblower
                protections are inadequate because they focus on illegal activities, while many of the risks we are
                concerned about are still unregulated," wrote the group.
                Their letter comes at a time when companies are rushing to implement generative AI tools in their
                products, while government regulators, businesses, and consumers struggle for responsible use.
                Meanwhile, many technology experts, researchers, and leaders have called for a temporary pause in the AI
                race, or for government intervention and a moratorium to be created.
                <br /><br /><br /><br />
                News written by: Samantha Murphy Kelly
                <br />
                CNN
            </p>

        </div>
    </div>

    <hr />

    <!--Video de la inteligencia artificial -->
    <div class="contenedor-vtexto">
        <h2> Reinforcement learning AI might bring humanoid robots to the real world </h2>
        <video controls autoplay class="video">
            <source src="playsoccer.mp4" type="video/mp4">
        </video>
        <p> “Soccer is a nice environment to study general reinforcement learning,” says Guy Lever of Google DeepMind, a
            coauthor of the paper. It requires planning, agility, exploration, cooperation and competition.
            The toy size of the robots “allowed us to iterate fast,” Haarnoja says, because larger robots are harder to
            operate and repair. And before deploying the machine learning software in the real robots — which can break
            when they fall over — the researchers trained it on virtual robots, a technique known as sim-to-real
            transfer.
            Training of the virtual bots came in two stages. In the first stage, the team trained one AI using RL merely
            to get the virtual robot up from the ground, and another to score goals without falling over. As input, the
            AIs received data including the positions and movements of the robots joints and, from external cameras,
            the positions of everything else in the game. (In a recently posted preprint, the team created a version of
            the system that relies on the robots own vision.) The AIs had to output new joint positions. If they
            performed well, their internal parameters were updated to encourage more of the same behavior. In the second
            stage, the researchers trained an AI to imitate each of the first two AIs and to score against closely
            matched opponents (versions of itself).
            To prepare the control software, called a controller, for the real-world robots, the researchers varied
            aspects of the simulation, including friction, sensor delays and body-mass distribution. They also rewarded
            the AI not just for scoring goals but also for other things, like minimizing knee torque to avoid injury.

            Real robots tested with the RL control software walked nearly twice as fast, turned three times as quickly
            and took less than half the time to get up compared with robots using the scripted controller made by the
            manufacturer. But more advanced skills also emerged, like fluidly stringing together actions. “It was really
            nice to see more complex motor skills being learned by robots,” says Radosavovic, who was not a part of the
            research. And the controller learned not just single moves, but also the planning required to play the game,
            like knowing to stand in the way of an opponent’s shot.

            “In my eyes, the soccer paper is amazing,” says Joonho Lee, a roboticist at ETH Zurich. “We’ve never seen
            such resilience from humanoids.”
            <br />
            News written by: Matthew Hutson.
            <br />
            Science News
        </p>
    </div>

    <hr />

    <p class="contenedor-vtexto"> ¡IMPORTANT! THE NEWS WAS TAKEN FROM WEB PAGES, CHECK THE BIBLIOGRAPHY SECTION TO SEE
        THE ORIGINALS. </p>

</body>

</html>